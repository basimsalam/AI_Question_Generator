# AI Question Paper Generator

## ğŸ“Š Technical Documentation

### ğŸ“… System Name

AI-Powered Question Paper Generator

### ğŸ’» Stack Overview

- **Backend Framework:** FastAPI
- **LLM:** LLaMA 3 (via Groq API)
- **Cache Layer:** Redis
- **Document Output:** PDF (fpdf), Word (python-docx)
- **Storage:** Local filesystem (with timestamps)

---

## ğŸ¢ Architecture Overview

```
                   Teacher UI (Frontend)
                           â¬‡ï¸
                     FastAPI Backend
         â”-------------------------------â”“
         |   /generate-paper (POST)         |
         |   /download/pdf/{timestamp}      |
         |   /topics, /subjects, /clear-cache|
         â”—-------------------------------â”›
               â”‚      â”‚          â”‚
               â”‚      â”‚          â””â”€â”€â”€> Groq (LLaMA 3)
               â”‚      â”‚
     Redis Cache     PDF/Word Generator
         (cache + pool)     (fpdf/docx)

Knowledge Base (JSON)
- Subjects â†’ Grades â†’ Topics
- Objectives and Facts
```

---

## ğŸ”„ Core Algorithms

### 1. Question Generation Loop

```python
for difficulty, count in difficulty_distribution.items():
    for _ in range(count):
        topic = next(topic_cycle)
        type = next(type_cycle)

        if cached:
            use_cached()
        else:
            kb_data = get_topic_knowledge(...)
            question = generate_from_llm(...)
            cache_question(...)

        if not duplicate:
            add_to_pool(...)
            paper.append(question)
```

### 2. LLM Prompt Template

```
Generate a {type} question.
Subject: {subject}  Grade: {grade}
Topic: {topic}  Difficulty: {difficulty}
Objectives: {kb_objectives}
Facts: {kb_facts}
```

### 3. Document Export

- Word: Headings + numbered questions
- PDF: Auto pagination, wrapped text

---

## ğŸ”— Components Explained

### FastAPI

- All routes and orchestration logic

### Generator (Groq)

- Uses LLaMA 3 model via `chat/completions`
- Prompt injected dynamically with context

### Redis

- `used_questions:{user_id}`: Prevents duplication
- `question_cache:{topic}:{difficulty}:{type}`: Caches generated questions

### Knowledge Base (KB)

- Stored in JSON: `/data/sample_kb.json`
- Contains topics, objectives, and facts
- Used to guide LLM outputs

### Document Generator

- `fpdf` for PDFs (paginated)
- `python-docx` for Word
- Files named like `question_paper_YYYYMMDDHHMMSS.pdf`

---

## ğŸš€ Scalability

- Redis hosted on Redis Cloud for scaling
- Stateless backend for Docker deployment
- LLM (Groq) supports high-throughput

---

## ğŸ“ Suggested Project Structure

```
app/
â”œâ”€â”€ main.py
â”œâ”€â”€ routes.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schema.py
â”œâ”€â”€ services/
â”‚   â””â”€â”€ generator.py
â”‚   â””â”€â”€ knowledge_base.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ caching.py
â”‚   â””â”€â”€ document_generator.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_kb.json
â”œâ”€â”€ generated_papers/
```

---

## ğŸ“„ Output Format Example

```json
{
  "paper": {
    "Question 1": "What is the by-product of photosynthesis?",
    "Question 2": "Define osmosis with an example."
  },
  "download_links": {
    "pdf": "/download/pdf/20250714122000",
    "word": "/download/word/20250714122000"
  }
}


